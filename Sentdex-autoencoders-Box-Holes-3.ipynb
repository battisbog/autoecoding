{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64844edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b986a205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coordinates</th>\n",
       "      <th>Young's modulus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0.0, 0.12]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.0, 0.24]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0.0, 0.36]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0.0, 0.48]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>[1.92, 1.44]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>[1.92, 1.56]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>[1.92, 1.68]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>[1.92, 1.7999999999999998]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>[1.92, 1.92]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>289 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    coordinates  Young's modulus\n",
       "0                    [0.0, 0.0]                2\n",
       "1                   [0.0, 0.12]                2\n",
       "2                   [0.0, 0.24]                2\n",
       "3                   [0.0, 0.36]                2\n",
       "4                   [0.0, 0.48]                2\n",
       "..                          ...              ...\n",
       "284                [1.92, 1.44]                2\n",
       "285                [1.92, 1.56]                2\n",
       "286                [1.92, 1.68]                2\n",
       "287  [1.92, 1.7999999999999998]                2\n",
       "288                [1.92, 1.92]                2\n",
       "\n",
       "[289 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loading the datasets to build the autoencoder\n",
    "\n",
    "training_data=pd.read_csv('sample-1.csv')\n",
    "#matrix = np.array(training_data)\n",
    "training_data.shape\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "072ce149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fadc00b20a0>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Extract the x and y coordinates from the \"coordinates\" column, ignoring the first row\n",
    "coordinates = np.array(training_data['coordinates'].iloc[1:])\n",
    "x_coords = np.array([ast.literal_eval(coord)[0] for coord in coordinates])\n",
    "y_coords = np.array([ast.literal_eval(coord)[1] for coord in coordinates])\n",
    "\n",
    "plt.plot(x_coords, y_coords, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3f5aad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x_coords\n",
    "x_coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67014941",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize the data to increase the encoders accuracy\n",
    "x_coords = x_coords/2\n",
    "y_coords = y_coords/2\n",
    "#x_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e913bf5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the Young's modulus values, ignoring the first row\n",
    "youngs_modulus = np.array(training_data[\"Young's modulus\"].iloc[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c96cad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#youngs_modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9f7aba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(288,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "youngs_modulus = youngs_modulus/2\n",
    "youngs_modulus.shape\n",
    "#youngs_modulus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38cbe0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Split the data into training and testing sets\n",
    "#Shuffle the data data before splitting to ensure that the training and testing sets\n",
    "#have a representative distribution of samples\n",
    "\n",
    "x_coords, y_coords, youngs_modulus = shuffle(x_coords, y_coords, youngs_modulus, random_state=42)\n",
    "\n",
    "x_split_index = int(0.5 * len(x_coords))\n",
    "y_split_index = int(0.5 * len(y_coords))\n",
    "x_train = x_coords[:x_split_index]\n",
    "y_train = y_coords[:y_split_index]\n",
    "z_train = youngs_modulus[:x_split_index]\n",
    "\n",
    "x_test = x_coords[x_split_index:]\n",
    "y_test = y_coords[y_split_index:]\n",
    "z_test = youngs_modulus[x_split_index:]\n",
    "len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e2221a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 144, 3)\n",
      "(1, 144, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[0.12, 0.72, 1.  ],\n",
       "        [0.54, 0.3 , 1.  ],\n",
       "        [0.9 , 0.12, 1.  ],\n",
       "        [0.12, 0.54, 1.  ],\n",
       "        [0.6 , 0.72, 1.  ],\n",
       "        [0.  , 0.6 , 1.  ],\n",
       "        [0.12, 0.78, 1.  ],\n",
       "        [0.6 , 0.18, 1.  ],\n",
       "        [0.24, 0.6 , 1.  ],\n",
       "        [0.66, 0.54, 1.  ],\n",
       "        [0.78, 0.12, 1.  ],\n",
       "        [0.12, 0.  , 1.  ],\n",
       "        [0.36, 0.9 , 1.  ],\n",
       "        [0.96, 0.48, 1.  ],\n",
       "        [0.18, 0.36, 1.  ],\n",
       "        [0.72, 0.78, 1.  ],\n",
       "        [0.  , 0.36, 1.  ],\n",
       "        [0.78, 0.24, 1.  ],\n",
       "        [0.84, 0.  , 1.  ],\n",
       "        [0.24, 0.48, 1.  ],\n",
       "        [0.9 , 0.78, 1.  ],\n",
       "        [0.3 , 0.  , 1.  ],\n",
       "        [0.36, 0.72, 1.  ],\n",
       "        [0.96, 0.9 , 1.  ],\n",
       "        [0.24, 0.36, 1.  ],\n",
       "        [0.84, 0.78, 1.  ],\n",
       "        [0.48, 0.3 , 1.  ],\n",
       "        [0.48, 0.72, 1.  ],\n",
       "        [0.36, 0.6 , 1.  ],\n",
       "        [0.18, 0.6 , 1.  ],\n",
       "        [0.36, 0.  , 1.  ],\n",
       "        [0.6 , 0.96, 1.  ],\n",
       "        [0.54, 0.12, 1.  ],\n",
       "        [0.78, 0.96, 1.  ],\n",
       "        [0.6 , 0.84, 1.  ],\n",
       "        [0.54, 0.96, 1.  ],\n",
       "        [0.78, 0.66, 1.  ],\n",
       "        [0.48, 0.48, 0.5 ],\n",
       "        [0.66, 0.96, 1.  ],\n",
       "        [0.36, 0.96, 1.  ],\n",
       "        [0.54, 0.78, 1.  ],\n",
       "        [0.9 , 0.  , 1.  ],\n",
       "        [0.54, 0.18, 1.  ],\n",
       "        [0.42, 0.84, 1.  ],\n",
       "        [0.06, 0.84, 1.  ],\n",
       "        [0.06, 0.36, 1.  ],\n",
       "        [0.06, 0.48, 1.  ],\n",
       "        [0.54, 0.36, 1.  ],\n",
       "        [0.48, 0.54, 0.5 ],\n",
       "        [0.54, 0.9 , 1.  ],\n",
       "        [0.84, 0.12, 1.  ],\n",
       "        [0.84, 0.96, 1.  ],\n",
       "        [0.3 , 0.78, 1.  ],\n",
       "        [0.72, 0.24, 1.  ],\n",
       "        [0.6 , 0.24, 1.  ],\n",
       "        [0.6 , 0.6 , 1.  ],\n",
       "        [0.96, 0.36, 1.  ],\n",
       "        [0.  , 0.42, 1.  ],\n",
       "        [0.3 , 0.54, 1.  ],\n",
       "        [0.18, 0.96, 1.  ],\n",
       "        [0.18, 0.78, 1.  ],\n",
       "        [0.24, 0.72, 1.  ],\n",
       "        [0.06, 0.54, 1.  ],\n",
       "        [0.66, 0.48, 1.  ],\n",
       "        [0.48, 0.66, 1.  ],\n",
       "        [0.9 , 0.06, 1.  ],\n",
       "        [0.06, 0.18, 1.  ],\n",
       "        [0.96, 0.54, 1.  ],\n",
       "        [0.3 , 0.48, 1.  ],\n",
       "        [0.  , 0.96, 1.  ],\n",
       "        [0.  , 0.66, 1.  ],\n",
       "        [0.72, 0.18, 1.  ],\n",
       "        [0.24, 0.06, 1.  ],\n",
       "        [0.36, 0.42, 1.  ],\n",
       "        [0.12, 0.24, 1.  ],\n",
       "        [0.06, 0.  , 1.  ],\n",
       "        [0.72, 0.6 , 1.  ],\n",
       "        [0.96, 0.18, 1.  ],\n",
       "        [0.9 , 0.36, 1.  ],\n",
       "        [0.24, 0.  , 1.  ],\n",
       "        [0.24, 0.9 , 1.  ],\n",
       "        [0.42, 0.  , 1.  ],\n",
       "        [0.72, 0.36, 1.  ],\n",
       "        [0.36, 0.48, 1.  ],\n",
       "        [0.72, 0.06, 1.  ],\n",
       "        [0.3 , 0.36, 1.  ],\n",
       "        [0.06, 0.12, 1.  ],\n",
       "        [0.78, 0.72, 1.  ],\n",
       "        [0.3 , 0.12, 1.  ],\n",
       "        [0.78, 0.18, 1.  ],\n",
       "        [0.84, 0.42, 1.  ],\n",
       "        [0.36, 0.66, 1.  ],\n",
       "        [0.96, 0.84, 1.  ],\n",
       "        [0.66, 0.  , 1.  ],\n",
       "        [0.18, 0.3 , 1.  ],\n",
       "        [0.42, 0.36, 1.  ],\n",
       "        [0.78, 0.48, 1.  ],\n",
       "        [0.12, 0.3 , 1.  ],\n",
       "        [0.6 , 0.36, 1.  ],\n",
       "        [0.42, 0.06, 1.  ],\n",
       "        [0.18, 0.42, 1.  ],\n",
       "        [0.36, 0.78, 1.  ],\n",
       "        [0.96, 0.3 , 1.  ],\n",
       "        [0.96, 0.06, 1.  ],\n",
       "        [0.84, 0.06, 1.  ],\n",
       "        [0.06, 0.9 , 1.  ],\n",
       "        [0.9 , 0.72, 1.  ],\n",
       "        [0.24, 0.66, 1.  ],\n",
       "        [0.72, 0.  , 1.  ],\n",
       "        [0.6 , 0.48, 0.5 ],\n",
       "        [0.78, 0.3 , 1.  ],\n",
       "        [0.9 , 0.42, 1.  ],\n",
       "        [0.3 , 0.72, 1.  ],\n",
       "        [0.9 , 0.66, 1.  ],\n",
       "        [0.42, 0.42, 0.5 ],\n",
       "        [0.66, 0.36, 1.  ],\n",
       "        [0.42, 0.48, 0.5 ],\n",
       "        [0.6 , 0.42, 1.  ],\n",
       "        [0.24, 0.12, 1.  ],\n",
       "        [0.96, 0.  , 1.  ],\n",
       "        [0.  , 0.18, 1.  ],\n",
       "        [0.36, 0.18, 1.  ],\n",
       "        [0.24, 0.54, 1.  ],\n",
       "        [0.36, 0.84, 1.  ],\n",
       "        [0.54, 0.72, 1.  ],\n",
       "        [0.48, 0.24, 1.  ],\n",
       "        [0.54, 0.42, 0.5 ],\n",
       "        [0.42, 0.12, 1.  ],\n",
       "        [0.78, 0.06, 1.  ],\n",
       "        [0.84, 0.3 , 1.  ],\n",
       "        [0.42, 0.54, 0.5 ],\n",
       "        [0.24, 0.42, 1.  ],\n",
       "        [0.06, 0.78, 1.  ],\n",
       "        [0.9 , 0.3 , 1.  ],\n",
       "        [0.72, 0.9 , 1.  ],\n",
       "        [0.36, 0.36, 1.  ],\n",
       "        [0.48, 0.12, 1.  ],\n",
       "        [0.48, 0.78, 1.  ],\n",
       "        [0.78, 0.42, 1.  ],\n",
       "        [0.6 , 0.06, 1.  ],\n",
       "        [0.66, 0.6 , 1.  ],\n",
       "        [0.18, 0.9 , 1.  ],\n",
       "        [0.6 , 0.54, 0.5 ],\n",
       "        [0.3 , 0.06, 1.  ]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the input data into a single tensor\n",
    "train_data = np.concatenate([x_train.reshape(-1, 144, 1), y_train.reshape(-1, 144, 1), z_train.reshape(-1, 144, 1)], axis=-1)\n",
    "test_data = np.concatenate([x_test.reshape(-1, 144, 1), y_test.reshape(-1, 144, 1), z_test.reshape(-1, 144, 1)], axis=-1)\n",
    "#train_data = np.concatenate([x_train, y_train, z_train], axis=-1)\n",
    "#test_data = np.concatenate([x_test, y_test, z_test], axis=-1)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6acdff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder_input (InputLayer)  [(None, 144, 3)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 432)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 72)                31176     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 36)                2628      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 72)                2664      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 432)               31536     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 144, 3)            0         \n",
      "                                                                 \n",
      " reshape_1 (Reshape)         (None, 144, 3)            0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 68,004\n",
      "Trainable params: 68,004\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-05 15:55:34.563842: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Define the shape of the input data\n",
    "input_shape = (144, 3)\n",
    "\n",
    "# Define the encoder network\n",
    "encoder_input = keras.Input(shape=input_shape, name='encoder_input')\n",
    "x = keras.layers.Flatten()(encoder_input)\n",
    "x = keras.layers.Dense(72, activation='relu')(x)\n",
    "encoder_output = keras.layers.Dense(36, activation='relu')(x)\n",
    "\n",
    "encoder= keras.Model(encoder_input, encoder_output, name= \"encoder\")\n",
    "\n",
    "# Define the decoder network\n",
    "decoder_input = keras.layers.Dense(72, activation='relu')(encoder_output)\n",
    "x = keras.layers.Dense(144*3, activation='sigmoid')(decoder_input)\n",
    "x = keras.layers.Reshape((144, 3))(x)\n",
    "decoder_output = keras.layers.Reshape((144, 3))(x)\n",
    "\n",
    "# Define the autoencoder model\n",
    "autoencoder = keras.Model(inputs=encoder_input, outputs=decoder_output, name='autoencoder')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "64362fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the autoencoder model\n",
    "autoencoder.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "40680284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 0s 325ms/step - loss: 0.0035 - val_loss: 0.2329\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0223 - val_loss: 0.2334\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0204 - val_loss: 0.2344\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0124 - val_loss: 0.2353\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0078 - val_loss: 0.2340\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0104 - val_loss: 0.2331\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0114 - val_loss: 0.2323\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0102 - val_loss: 0.2319\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0093 - val_loss: 0.2324\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0074 - val_loss: 0.2334\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0061 - val_loss: 0.2338\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.2337\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0065 - val_loss: 0.2328\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0063 - val_loss: 0.2320\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0060 - val_loss: 0.2314\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0055 - val_loss: 0.2315\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0048 - val_loss: 0.2320\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.2324\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0045 - val_loss: 0.2325\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0043 - val_loss: 0.2322\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0046 - val_loss: 0.2320\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0043 - val_loss: 0.2318\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0039 - val_loss: 0.2319\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.2320\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0036 - val_loss: 0.2320\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.2320\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0037 - val_loss: 0.2319\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0036 - val_loss: 0.2320\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0034 - val_loss: 0.2321\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0033 - val_loss: 0.2320\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0032 - val_loss: 0.2318\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.2317\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0031 - val_loss: 0.2318\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0032 - val_loss: 0.2320\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0030 - val_loss: 0.2321\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.2321\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0027 - val_loss: 0.2319\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.2319\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.2320\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0027 - val_loss: 0.2319\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0028 - val_loss: 0.2318\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0026 - val_loss: 0.2317\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.2319\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0027 - val_loss: 0.2322\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0027 - val_loss: 0.2322\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.0025 - val_loss: 0.2322\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.2322\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0023 - val_loss: 0.2320\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0024 - val_loss: 0.2318\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.0025 - val_loss: 0.2316\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.0025 - val_loss: 0.2315\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 0.2316\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.2318\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0025 - val_loss: 0.2322\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.2323\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0026 - val_loss: 0.2321\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.2319\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.2318\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.2319\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.0025 - val_loss: 0.2319\n",
      "Epoch 61/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.2319\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2321\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.0024 - val_loss: 0.2323\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.2322\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.2319\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.2317\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2318\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.2321\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0023 - val_loss: 0.2320\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.2319\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.2318\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.2318\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.2318\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.2318\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.2320\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2322\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2320\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0021 - val_loss: 0.2319\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.2318\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2319\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2318\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.2318\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.2319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.2321\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.2322\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.2321\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0023 - val_loss: 0.2319\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.2317\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0021 - val_loss: 0.2317\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0022 - val_loss: 0.2315\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2317\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 15ms/step - loss: 0.0024 - val_loss: 0.2319\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2319\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0020 - val_loss: 0.2318\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.2319\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0023 - val_loss: 0.2321\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0025 - val_loss: 0.2320\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.0024 - val_loss: 0.2317\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0024 - val_loss: 0.2316\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0022 - val_loss: 0.2316\n"
     ]
    }
   ],
   "source": [
    "# Train the autoencoder\n",
    "history = autoencoder.fit(x=train_data, y=train_data,\n",
    "                          epochs=100, batch_size=32, shuffle=True, validation_data=(test_data, test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aeaa0212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.66 0.42 1.  ]\n",
      "  [0.   0.78 1.  ]\n",
      "  [0.12 0.12 1.  ]\n",
      "  [0.06 0.72 1.  ]\n",
      "  [0.48 0.42 0.5 ]\n",
      "  [0.78 0.54 1.  ]\n",
      "  [0.54 0.   1.  ]\n",
      "  [0.18 0.06 1.  ]\n",
      "  [0.3  0.66 1.  ]\n",
      "  [0.96 0.72 1.  ]\n",
      "  [0.66 0.84 1.  ]\n",
      "  [0.12 0.48 1.  ]\n",
      "  [0.84 0.54 1.  ]\n",
      "  [0.66 0.66 1.  ]\n",
      "  [0.48 0.06 1.  ]\n",
      "  [0.06 0.6  1.  ]\n",
      "  [0.96 0.6  1.  ]\n",
      "  [0.48 0.36 1.  ]\n",
      "  [0.6  0.66 1.  ]\n",
      "  [0.   0.06 1.  ]\n",
      "  [0.9  0.24 1.  ]\n",
      "  [0.3  0.96 1.  ]\n",
      "  [0.9  0.84 1.  ]\n",
      "  [0.78 0.6  1.  ]\n",
      "  [0.3  0.84 1.  ]\n",
      "  [0.12 0.18 1.  ]\n",
      "  [0.18 0.66 1.  ]\n",
      "  [0.48 0.9  1.  ]\n",
      "  [0.72 0.54 1.  ]\n",
      "  [0.6  0.78 1.  ]\n",
      "  [0.72 0.96 1.  ]\n",
      "  [0.   0.72 1.  ]\n",
      "  [0.96 0.78 1.  ]\n",
      "  [0.96 0.12 1.  ]\n",
      "  [0.06 0.66 1.  ]\n",
      "  [0.72 0.42 1.  ]\n",
      "  [0.   0.3  1.  ]\n",
      "  [0.42 0.24 1.  ]\n",
      "  [0.06 0.96 1.  ]\n",
      "  [0.6  0.9  1.  ]\n",
      "  [0.54 0.6  0.5 ]\n",
      "  [0.72 0.3  1.  ]\n",
      "  [0.78 0.78 1.  ]\n",
      "  [0.48 0.18 1.  ]\n",
      "  [0.18 0.72 1.  ]\n",
      "  [0.48 0.   1.  ]\n",
      "  [0.42 0.6  1.  ]\n",
      "  [0.96 0.42 1.  ]\n",
      "  [0.84 0.6  1.  ]\n",
      "  [0.24 0.18 1.  ]\n",
      "  [0.84 0.84 1.  ]\n",
      "  [0.18 0.84 1.  ]\n",
      "  [0.12 0.66 1.  ]\n",
      "  [0.72 0.48 1.  ]\n",
      "  [0.54 0.24 1.  ]\n",
      "  [0.12 0.42 1.  ]\n",
      "  [0.42 0.3  1.  ]\n",
      "  [0.84 0.18 1.  ]\n",
      "  [0.54 0.06 1.  ]\n",
      "  [0.06 0.42 1.  ]\n",
      "  [0.84 0.48 1.  ]\n",
      "  [0.84 0.66 1.  ]\n",
      "  [0.24 0.84 1.  ]\n",
      "  [0.12 0.36 1.  ]\n",
      "  [0.72 0.72 1.  ]\n",
      "  [0.78 0.84 1.  ]\n",
      "  [0.66 0.78 1.  ]\n",
      "  [0.   0.9  1.  ]\n",
      "  [0.12 0.84 1.  ]\n",
      "  [0.3  0.6  1.  ]\n",
      "  [0.84 0.72 1.  ]\n",
      "  [0.9  0.54 1.  ]\n",
      "  [0.66 0.9  1.  ]\n",
      "  [0.54 0.54 0.5 ]\n",
      "  [0.12 0.6  1.  ]\n",
      "  [0.72 0.84 1.  ]\n",
      "  [0.48 0.6  0.5 ]\n",
      "  [0.66 0.24 1.  ]\n",
      "  [0.78 0.   1.  ]\n",
      "  [0.78 0.36 1.  ]\n",
      "  [0.   0.24 1.  ]\n",
      "  [0.36 0.24 1.  ]\n",
      "  [0.18 0.18 1.  ]\n",
      "  [0.42 0.9  1.  ]\n",
      "  [0.   0.12 1.  ]\n",
      "  [0.9  0.9  1.  ]\n",
      "  [0.36 0.12 1.  ]\n",
      "  [0.12 0.96 1.  ]\n",
      "  [0.54 0.66 1.  ]\n",
      "  [0.24 0.78 1.  ]\n",
      "  [0.72 0.12 1.  ]\n",
      "  [0.12 0.06 1.  ]\n",
      "  [0.9  0.48 1.  ]\n",
      "  [0.   0.48 1.  ]\n",
      "  [0.6  0.12 1.  ]\n",
      "  [0.66 0.72 1.  ]\n",
      "  [0.9  0.6  1.  ]\n",
      "  [0.36 0.54 1.  ]\n",
      "  [0.3  0.42 1.  ]\n",
      "  [0.24 0.96 1.  ]\n",
      "  [0.42 0.66 1.  ]\n",
      "  [0.18 0.12 1.  ]\n",
      "  [0.3  0.3  1.  ]\n",
      "  [0.   0.54 1.  ]\n",
      "  [0.84 0.24 1.  ]\n",
      "  [0.   0.84 1.  ]\n",
      "  [0.18 0.54 1.  ]\n",
      "  [0.3  0.24 1.  ]\n",
      "  [0.42 0.78 1.  ]\n",
      "  [0.06 0.06 1.  ]\n",
      "  [0.54 0.84 1.  ]\n",
      "  [0.24 0.3  1.  ]\n",
      "  [0.96 0.66 1.  ]\n",
      "  [0.42 0.96 1.  ]\n",
      "  [0.96 0.24 1.  ]\n",
      "  [0.84 0.36 1.  ]\n",
      "  [0.18 0.24 1.  ]\n",
      "  [0.18 0.   1.  ]\n",
      "  [0.6  0.3  1.  ]\n",
      "  [0.66 0.18 1.  ]\n",
      "  [0.66 0.06 1.  ]\n",
      "  [0.6  0.   1.  ]\n",
      "  [0.18 0.48 1.  ]\n",
      "  [0.12 0.9  1.  ]\n",
      "  [0.78 0.9  1.  ]\n",
      "  [0.84 0.9  1.  ]\n",
      "  [0.06 0.3  1.  ]\n",
      "  [0.54 0.48 0.5 ]\n",
      "  [0.66 0.3  1.  ]\n",
      "  [0.9  0.18 1.  ]\n",
      "  [0.48 0.84 1.  ]\n",
      "  [0.42 0.72 1.  ]\n",
      "  [0.48 0.96 1.  ]\n",
      "  [0.3  0.9  1.  ]\n",
      "  [0.3  0.18 1.  ]\n",
      "  [0.72 0.66 1.  ]\n",
      "  [0.42 0.18 1.  ]\n",
      "  [0.96 0.96 1.  ]\n",
      "  [0.06 0.24 1.  ]\n",
      "  [0.66 0.12 1.  ]\n",
      "  [0.24 0.24 1.  ]\n",
      "  [0.36 0.3  1.  ]\n",
      "  [0.9  0.96 1.  ]\n",
      "  [0.36 0.06 1.  ]]]\n"
     ]
    }
   ],
   "source": [
    "#Printing the original test data to comapare with the predicted data set later\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5908c1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "Reduced data has shape of: (1, 36)\n",
      "[[0.        0.        7.3011074 0.        0.        0.        0.\n",
      "  0.        0.        2.2031088 0.        0.        0.        3.4422832\n",
      "  3.6486335 0.        3.292997  0.        2.5648177 2.5466216 4.595363\n",
      "  0.        0.        0.634042  0.        6.070576  4.923232  0.\n",
      "  0.        6.6170106 4.3905063 1.1148068 4.47405   0.        0.\n",
      "  0.       ]]\n"
     ]
    }
   ],
   "source": [
    "#Running the encoder just to observe the encoded or reduced data set\n",
    "reduced_data=encoder.predict(test_data)\n",
    "print(\"Reduced data has shape of:\", reduced_data.shape)\n",
    "print(reduced_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2130211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 54ms/step\n",
      "(1, 144, 3)\n",
      "[[[1.2632976e-01 7.0494193e-01 9.9972159e-01]\n",
      "  [5.1555616e-01 3.1812257e-01 9.9969703e-01]\n",
      "  [8.9237875e-01 1.2685829e-01 9.9965459e-01]\n",
      "  [1.3000999e-01 5.3570491e-01 9.9963516e-01]\n",
      "  [6.1612898e-01 7.1107936e-01 9.9965000e-01]\n",
      "  [2.8536012e-04 5.9265482e-01 9.9979919e-01]\n",
      "  [1.3356584e-01 7.7240986e-01 9.9988663e-01]\n",
      "  [5.9428495e-01 1.8586196e-01 9.9980903e-01]\n",
      "  [2.5493014e-01 6.0042423e-01 9.9973184e-01]\n",
      "  [6.6704273e-01 4.9957374e-01 9.9974591e-01]\n",
      "  [7.7923065e-01 1.2749876e-01 9.9952036e-01]\n",
      "  [1.2423470e-01 1.7073403e-04 9.9960822e-01]\n",
      "  [3.7948638e-01 8.9857858e-01 9.9982995e-01]\n",
      "  [9.5243299e-01 4.6060666e-01 9.9973947e-01]\n",
      "  [1.9070148e-01 3.5925201e-01 9.9985617e-01]\n",
      "  [7.0438081e-01 7.5571561e-01 9.9975473e-01]\n",
      "  [3.0838509e-04 3.7579188e-01 9.9974740e-01]\n",
      "  [7.6817280e-01 2.4226606e-01 9.9961847e-01]\n",
      "  [8.3376223e-01 2.6216358e-04 9.9995029e-01]\n",
      "  [2.3827919e-01 4.6283346e-01 9.9953049e-01]\n",
      "  [8.9751595e-01 7.8782225e-01 9.9968117e-01]\n",
      "  [3.0489317e-01 2.1436815e-04 9.9970853e-01]\n",
      "  [3.7262228e-01 7.0026189e-01 9.9977016e-01]\n",
      "  [9.5392263e-01 8.9356369e-01 9.9978268e-01]\n",
      "  [2.5478396e-01 3.8070509e-01 9.9976665e-01]\n",
      "  [8.3739543e-01 7.7250195e-01 9.9976647e-01]\n",
      "  [4.8658633e-01 3.0744812e-01 9.9974000e-01]\n",
      "  [4.6797574e-01 6.9825286e-01 9.9972254e-01]\n",
      "  [3.5500905e-01 6.0197592e-01 9.9975914e-01]\n",
      "  [1.8390870e-01 6.1792362e-01 9.9971944e-01]\n",
      "  [3.8410959e-01 1.1711986e-04 9.9976003e-01]\n",
      "  [6.0004300e-01 9.5410478e-01 9.9986279e-01]\n",
      "  [5.4734796e-01 1.2911849e-01 9.9966317e-01]\n",
      "  [7.7766389e-01 9.5705462e-01 9.9978244e-01]\n",
      "  [5.8698946e-01 8.2878435e-01 9.9976933e-01]\n",
      "  [5.3339601e-01 9.5217687e-01 9.9967307e-01]\n",
      "  [7.7374393e-01 6.5722197e-01 9.9975026e-01]\n",
      "  [4.7184083e-01 4.6869206e-01 5.0900209e-01]\n",
      "  [6.5068132e-01 9.5787543e-01 9.9974382e-01]\n",
      "  [3.4934863e-01 9.5357168e-01 9.9965048e-01]\n",
      "  [5.1224446e-01 7.7299577e-01 9.9970585e-01]\n",
      "  [8.9528114e-01 2.2069615e-05 9.9981040e-01]\n",
      "  [5.4977554e-01 1.9362079e-01 9.9985373e-01]\n",
      "  [4.2307192e-01 8.3016503e-01 9.9973893e-01]\n",
      "  [5.9419733e-02 8.3542275e-01 9.9979979e-01]\n",
      "  [6.4537130e-02 3.5150740e-01 9.9964815e-01]\n",
      "  [6.6065021e-02 4.7093993e-01 9.9977189e-01]\n",
      "  [5.5373710e-01 3.7773377e-01 9.9965072e-01]\n",
      "  [4.7613943e-01 5.3896558e-01 5.2967680e-01]\n",
      "  [5.4165417e-01 8.9105737e-01 9.9986476e-01]\n",
      "  [8.2500058e-01 1.2834805e-01 9.9980050e-01]\n",
      "  [8.3238411e-01 9.5709991e-01 9.9970716e-01]\n",
      "  [3.1365597e-01 7.6277560e-01 9.9979818e-01]\n",
      "  [7.0760059e-01 2.4784654e-01 9.9982667e-01]\n",
      "  [5.8815610e-01 2.4336067e-01 9.9969399e-01]\n",
      "  [5.9581488e-01 5.9389710e-01 9.9982375e-01]\n",
      "  [9.5451945e-01 3.6680275e-01 9.9975866e-01]\n",
      "  [1.7815303e-04 4.2259771e-01 9.9964517e-01]\n",
      "  [3.0907676e-01 5.4353666e-01 9.9939233e-01]\n",
      "  [1.9506380e-01 9.5633525e-01 9.9949855e-01]\n",
      "  [2.0140368e-01 7.7238888e-01 9.9958384e-01]\n",
      "  [2.5745505e-01 7.1017915e-01 9.9977767e-01]\n",
      "  [6.3659631e-02 5.3532374e-01 9.9987042e-01]\n",
      "  [6.5986985e-01 4.7547108e-01 9.9991024e-01]\n",
      "  [4.5513394e-01 6.5236318e-01 9.9974239e-01]\n",
      "  [8.9522469e-01 6.6592216e-02 9.9957776e-01]\n",
      "  [6.1521567e-02 1.9486232e-01 9.9981076e-01]\n",
      "  [9.5567590e-01 5.4744583e-01 9.9980134e-01]\n",
      "  [2.9890552e-01 4.8113605e-01 9.9957997e-01]\n",
      "  [6.9649854e-05 9.5101613e-01 9.9972999e-01]\n",
      "  [3.8090014e-04 6.5539640e-01 9.9983096e-01]\n",
      "  [7.1580666e-01 2.0340627e-01 9.9966425e-01]\n",
      "  [2.4598284e-01 6.5319650e-02 9.9975270e-01]\n",
      "  [3.4163457e-01 4.2306665e-01 9.9983567e-01]\n",
      "  [1.2754929e-01 2.4930200e-01 9.9952906e-01]\n",
      "  [6.2351275e-02 1.4220319e-04 9.9953151e-01]\n",
      "  [6.9821525e-01 5.8541566e-01 9.9989933e-01]\n",
      "  [9.5795387e-01 1.9024529e-01 9.9983966e-01]\n",
      "  [8.9470148e-01 3.4698245e-01 9.9972534e-01]\n",
      "  [2.5366834e-01 4.0181130e-04 9.9979281e-01]\n",
      "  [2.4265805e-01 8.8549954e-01 9.9973774e-01]\n",
      "  [4.2609343e-01 3.4714106e-04 9.9963921e-01]\n",
      "  [6.9274926e-01 3.6970311e-01 9.9962139e-01]\n",
      "  [3.8614225e-01 4.6055698e-01 9.9956739e-01]\n",
      "  [6.8493611e-01 6.4726211e-02 9.9962932e-01]\n",
      "  [3.0370396e-01 3.8087848e-01 9.9992889e-01]\n",
      "  [6.4824119e-02 1.3689448e-01 9.9968714e-01]\n",
      "  [7.7606755e-01 7.0670372e-01 9.9976969e-01]\n",
      "  [3.1580356e-01 1.2907626e-01 9.9961805e-01]\n",
      "  [7.7699524e-01 1.7321512e-01 9.9987012e-01]\n",
      "  [8.3343214e-01 4.3823242e-01 9.9983442e-01]\n",
      "  [3.8201892e-01 6.6311324e-01 9.9985242e-01]\n",
      "  [9.5757788e-01 8.3366728e-01 9.9984443e-01]\n",
      "  [6.5354937e-01 9.9916411e-05 9.9970728e-01]\n",
      "  [2.0043802e-01 3.2910353e-01 9.9995309e-01]\n",
      "  [4.1467687e-01 3.7752390e-01 9.9973333e-01]\n",
      "  [7.8188378e-01 4.6562776e-01 9.9971795e-01]\n",
      "  [1.3179845e-01 3.0194530e-01 9.9974936e-01]\n",
      "  [6.3120520e-01 3.6137435e-01 9.9943513e-01]\n",
      "  [4.0650737e-01 6.2009495e-02 9.9971753e-01]\n",
      "  [1.8415785e-01 4.2961797e-01 9.9964058e-01]\n",
      "  [3.8518724e-01 7.6895493e-01 9.9961120e-01]\n",
      "  [9.5778733e-01 2.9211852e-01 9.9966717e-01]\n",
      "  [9.5286429e-01 6.7325436e-02 9.9969089e-01]\n",
      "  [8.3907223e-01 6.2693886e-02 9.9958885e-01]\n",
      "  [6.4306326e-02 8.9944953e-01 9.9978286e-01]\n",
      "  [8.9436352e-01 7.1204692e-01 9.9989367e-01]\n",
      "  [2.4247696e-01 6.4120364e-01 9.9980175e-01]\n",
      "  [7.2032082e-01 3.2557300e-04 9.9973333e-01]\n",
      "  [5.9928179e-01 4.6141163e-01 5.3758329e-01]\n",
      "  [7.7979034e-01 3.1343511e-01 9.9990201e-01]\n",
      "  [8.9566195e-01 4.1788542e-01 9.9980521e-01]\n",
      "  [3.0027783e-01 7.2201049e-01 9.9970800e-01]\n",
      "  [8.9117295e-01 6.6909635e-01 9.9963188e-01]\n",
      "  [4.1922611e-01 4.0863511e-01 5.0326252e-01]\n",
      "  [6.8118709e-01 3.6373100e-01 9.9970931e-01]\n",
      "  [4.2599589e-01 4.9513665e-01 4.9741194e-01]\n",
      "  [5.9484386e-01 4.3048361e-01 9.9964440e-01]\n",
      "  [2.5285941e-01 1.2442414e-01 9.9974501e-01]\n",
      "  [9.5593697e-01 4.0703051e-04 9.9996489e-01]\n",
      "  [2.2524490e-04 1.8415965e-01 9.9967015e-01]\n",
      "  [3.4698579e-01 1.8430029e-01 9.9953294e-01]\n",
      "  [2.4848133e-01 5.3349715e-01 9.9971539e-01]\n",
      "  [3.7416002e-01 8.3212757e-01 9.9970162e-01]\n",
      "  [5.6231147e-01 7.2029716e-01 9.9979711e-01]\n",
      "  [4.7262245e-01 2.4012540e-01 9.9986285e-01]\n",
      "  [5.3057158e-01 4.1073787e-01 5.2085245e-01]\n",
      "  [4.2196131e-01 1.2020825e-01 9.9968988e-01]\n",
      "  [7.7085894e-01 6.5608457e-02 9.9955839e-01]\n",
      "  [8.4586245e-01 3.1989673e-01 9.9960136e-01]\n",
      "  [4.4710335e-01 5.6341493e-01 5.1398623e-01]\n",
      "  [2.4231529e-01 4.1925079e-01 9.9969244e-01]\n",
      "  [6.0491614e-02 7.8067642e-01 9.9982882e-01]\n",
      "  [8.9411038e-01 2.8831869e-01 9.9987429e-01]\n",
      "  [6.9292480e-01 8.8589710e-01 9.9993557e-01]\n",
      "  [3.6517376e-01 3.4151784e-01 9.9994850e-01]\n",
      "  [4.7487125e-01 1.3011262e-01 9.9957740e-01]\n",
      "  [4.7954401e-01 7.8606451e-01 9.9981397e-01]\n",
      "  [7.8586251e-01 4.2280239e-01 9.9964303e-01]\n",
      "  [6.1929101e-01 6.5611564e-02 9.9991131e-01]\n",
      "  [6.4581585e-01 6.0915953e-01 9.9993932e-01]\n",
      "  [1.8748645e-01 8.9208180e-01 9.9965340e-01]\n",
      "  [5.8444017e-01 5.3562051e-01 5.0986993e-01]\n",
      "  [2.9834533e-01 6.6252321e-02 9.9972242e-01]]]\n"
     ]
    }
   ],
   "source": [
    "# Use the trained autoencoder to predict on the test data\n",
    "predicted_data = autoencoder.predict(test_data)\n",
    "\n",
    "# Print the shape of the predicted data\n",
    "print(predicted_data.shape)\n",
    "print(predicted_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a67d2192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error: 0.23159734784068742\n",
      "Percentage error: inf %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/szb78kyd2cnd60qwd0m1rzvc0000gn/T/ipykernel_73900/883995133.py:8: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  pct_error = np.mean(np.abs(diff) / test_data) * 100\n"
     ]
    }
   ],
   "source": [
    "# Calculate the difference between predicted_data and test_data\n",
    "diff = predicted_data - test_data\n",
    "\n",
    "# Calculate the mean absolute error\n",
    "mae = np.mean(np.abs(diff))\n",
    "\n",
    "# Calculate the percentage error\n",
    "pct_error = np.mean(np.abs(diff) / test_data) * 100\n",
    "\n",
    "print(\"Mean absolute error:\", mae)\n",
    "print(\"Percentage error:\", pct_error, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23f18d07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12103636795925304\n",
      "[[[9.02683903e+01 7.91593858e+01 1.68717504e+00]\n",
      "  [           inf 5.96676078e+01 1.86506510e+00]\n",
      "  [7.13552290e+02 2.97050449e+01 2.39439011e+00]\n",
      "  [6.53067271e+01 2.60046995e+01 2.57743597e+00]\n",
      "  [2.51735414e+01 4.68452811e+01 9.56853747e+01]\n",
      "  [9.80575705e+01 1.51199363e+01 1.19376183e+00]\n",
      "  [9.50531753e+01            inf 4.45562601e-01]\n",
      "  [2.26899158e+02 3.07275061e+02 8.42291117e-01]\n",
      "  [3.37152441e+01 1.05551207e+01 1.84536576e+00]\n",
      "  [3.29431665e+01 2.84658581e+01 1.32718682e+00]\n",
      "  [1.05922912e+01 9.40432573e+01 3.84953022e+00]\n",
      "  [3.94538191e+01 9.83692598e+01 2.93358564e+00]\n",
      "  [5.43489551e+01 8.27072987e+01 8.24433565e-01]\n",
      "  [4.45928306e+01 2.85449359e+01 1.72855854e+00]\n",
      "  [6.36703512e+01 4.22256841e+02 6.57773018e-01]\n",
      "  [9.51353912e+02 1.92876697e+01 1.20344162e+00]\n",
      "  [9.74057144e+01 3.45041265e+01 1.35239363e+00]\n",
      "  [5.12830580e+01 3.39263224e+01 3.34298015e+00]\n",
      "  [4.91464178e+01 9.73510841e+01 1.37364864e-01]\n",
      "  [           inf 6.97982415e+02 2.99007297e+00]\n",
      "  [4.57691881e+00 2.04948017e+02 2.75132656e+00]\n",
      "  [1.84585253e+00 9.87319837e+01 1.75338984e+00]\n",
      "  [6.37600217e+01 1.69548282e+01 1.54699683e+00]\n",
      "  [2.15902429e+01 6.05510910e+01 1.53948069e+00]\n",
      "  [1.34358267e+01 6.21171930e+01 1.91136599e+00]\n",
      "  [5.99038357e+02 3.40976686e+02 1.36859417e+00]\n",
      "  [1.66137752e+02 5.08427083e+01 1.35858655e+00]\n",
      "  [1.96422984e+00 1.74111154e+01 2.16050744e+00]\n",
      "  [5.47126517e+01 1.93709064e+01 1.39846802e+00]\n",
      "  [7.44711444e+01 1.94562970e+01 2.30548382e+00]\n",
      "  [5.48099687e+01 9.94609726e+01 1.51458979e+00]\n",
      "  [           inf 3.75108543e+01 6.01935387e-01]\n",
      "  [3.77286620e+01 8.69700617e+01 2.58814096e+00]\n",
      "  [2.21969458e+01 7.27607910e+02 1.42185688e+00]\n",
      "  [9.86292863e+02 3.78211740e+01 1.20549202e+00]\n",
      "  [2.62245082e+01 1.32500689e+02 2.44589448e+00]\n",
      "  [           inf 1.30121672e+02 1.36245489e+00]\n",
      "  [1.34910186e+01 9.22847827e+01 4.87666190e+01]\n",
      "  [1.06524021e+03 3.25974474e+00 1.87368393e+00]\n",
      "  [4.06106472e+01 6.57093922e+00 2.20801830e+00]\n",
      "  [7.28156434e+00 1.66770061e+01 9.58923936e+01]\n",
      "  [3.54238556e+01 9.98353407e+01 9.62150097e-01]\n",
      "  [2.74561650e+01 7.06761826e+01 7.40951300e-01]\n",
      "  [2.05941334e+01 3.76139320e+02 1.45645738e+00]\n",
      "  [9.23850099e+01 3.53235791e+01 1.08035207e+00]\n",
      "  [9.56494271e+01            inf 2.67876387e+00]\n",
      "  [9.26304232e+01 2.23804673e+01 1.18212700e+00]\n",
      "  [4.05494456e+01 2.94531697e+00 2.95596123e+00]\n",
      "  [4.31483980e+01 9.02485450e+00 4.61836755e+01]\n",
      "  [1.28920355e+02 4.47280875e+02 6.54494762e-01]\n",
      "  [4.94644443e+00 9.81004922e+01 8.96000862e-01]\n",
      "  [4.07095754e+02 1.46371308e+01 2.22076178e+00]\n",
      "  [1.33129983e+02 1.77724835e+01 1.12301111e+00]\n",
      "  [3.52615118e-01 3.91717898e+01 7.38930702e-01]\n",
      "  [1.18672446e+01 6.73594971e+00 1.80183053e+00]\n",
      "  [3.95071014e+02 4.45418171e+01 9.14508104e-01]\n",
      "  [1.29552175e+02 2.57744431e+01 1.35035515e+00]\n",
      "  [9.89804303e+01 1.40760810e+02 2.43368745e+00]\n",
      "  [3.36823269e+01 7.99090866e+02 4.96045351e+00]\n",
      "  [2.71122037e+02 1.28407326e+02 3.75298262e+00]\n",
      "  [6.84777927e+01 4.57695290e+01 3.21657658e+00]\n",
      "  [6.86997135e+01 1.04972670e+01 1.20660663e+00]\n",
      "  [8.09962604e+01 3.79779398e+01 5.21689653e-01]\n",
      "  [4.21565576e+02 3.25088822e+01 3.23683023e-01]\n",
      "  [3.49097825e+01 5.42871257e+00 1.20435953e+00]\n",
      "  [2.22744431e+01 9.31872162e+01 2.92845368e+00]\n",
      "  [9.57914724e+01 6.95184789e+01 9.33396816e-01]\n",
      "  [           inf 4.08569998e+01 8.51887465e-01]\n",
      "  [1.22152099e+02 4.38289588e+01 3.54152918e+00]\n",
      "  [9.91582022e+01 6.14779433e+01 2.11356282e+00]\n",
      "  [9.63138368e+01 2.68545846e+00 9.70065594e-01]\n",
      "  [1.87739491e+01 5.05787591e+01 2.27298141e+00]\n",
      "  [6.46703357e+01 9.66014504e+01 1.55103803e+00]\n",
      "  [3.21298356e+01 2.38713030e+01 9.85419989e+01]\n",
      "  [9.49761713e+01 5.14372299e+01 2.99065709e+00]\n",
      "  [9.77537726e+01 9.91819822e+01 3.57706547e+00]\n",
      "  [5.17717292e+01 7.88782636e+00 9.90778327e+01]\n",
      "  [4.93947434e+01 8.40728504e+01 7.49176741e-01]\n",
      "  [2.16893548e+01            inf 1.89642906e+00]\n",
      "  [7.08236716e+01 9.30910026e+01 1.28926635e+00]\n",
      "  [           inf 2.89558176e+02 1.43628120e+00]\n",
      "  [2.30464958e+01 9.08836923e+01 3.53451967e+00]\n",
      "  [3.15135125e+02 8.20336945e+01 2.89071798e+00]\n",
      "  [1.50406392e+01 4.87648110e+01 3.41865420e+00]\n",
      "  [           inf 5.41225346e+01 2.66430378e+00]\n",
      "  [6.97673851e+01 5.65721320e+01 2.38806009e-01]\n",
      "  [9.40571137e+01 3.30221241e+01 2.66786218e+00]\n",
      "  [5.61308815e+02 2.15808635e+01 1.11688375e+00]\n",
      "  [4.97391504e+01 8.86013251e+01 2.63481140e+00]\n",
      "  [1.91486879e+02 7.40984119e+01 5.56862354e-01]\n",
      "  [2.62684249e+01 2.87398923e+02 8.11690092e-01]\n",
      "  [1.86910608e+02 1.02805188e+03 7.89403915e-01]\n",
      "  [5.84581561e+00 6.87543963e+01 6.79188967e-01]\n",
      "  [           inf 9.90984221e+01 1.94649696e+00]\n",
      "  [6.23889923e+01 1.25800524e+02 1.55025721e-01]\n",
      "  [3.99990972e+01 5.28723210e+01 1.43694282e+00]\n",
      "  [1.41100446e+01 2.28090892e+01 1.86407566e+00]\n",
      "  [7.57373685e+01 5.13255998e+01 1.90532804e+00]\n",
      "  [9.76561944e+01 6.44102295e+00 4.78864312e+00]\n",
      "  [8.23223134e+01 9.73265396e+01 1.94439888e+00]\n",
      "  [7.28226289e+01 3.30657179e+01 3.05606723e+00]\n",
      "  [1.06277751e+02 5.07079516e+02 3.27638984e+00]\n",
      "  [2.30903848e+02 1.56382084e+01 2.27508545e+00]\n",
      "  [           inf 9.09237117e+01 1.95652843e+00]\n",
      "  [8.71152083e+00 8.94862754e+01 3.23237777e+00]\n",
      "  [           inf 1.32007227e+01 1.05109811e+00]\n",
      "  [4.17125560e+02 5.59790196e+01 4.57870960e-01]\n",
      "  [1.70587262e+01 1.74480854e+02 8.98820162e-01]\n",
      "  [7.69541843e+01 9.73141615e+01 2.01230049e+00]\n",
      "  [8.69127516e+02 6.72450864e+02 4.50792670e+01]\n",
      "  [3.40509344e+01 6.86315869e+01 4.09245491e-01]\n",
      "  [3.14651831e+02 5.28077026e+01 9.26446915e-01]\n",
      "  [6.06836090e+01 1.40350013e+01 1.91229582e+00]\n",
      "  [1.28497258e+02 2.92726008e+01 2.73442864e+00]\n",
      "  [5.44634453e+01 6.15365967e+01 5.02528429e+01]\n",
      "  [1.61032410e+01 3.51509717e+00 1.83004141e+00]\n",
      "  [1.43239899e+02 9.98285204e+01 5.02310306e+01]\n",
      "  [2.19866671e+02            inf 2.14111805e+00]\n",
      "  [5.24758160e+01 8.42991692e+01 1.35200024e+00]\n",
      "  [4.56227808e+01 8.54375225e+01 9.04023647e-02]\n",
      "  [9.75925405e+01 3.04060682e+02 2.55240202e+00]\n",
      "  [5.03884365e+01            inf 3.78264785e+00]\n",
      "  [2.66973797e+01 1.21621331e+01 1.36762857e+00]\n",
      "  [1.76989167e+02 1.08829313e+01 2.60921121e+00]\n",
      "  [2.80183820e+01 1.61131912e+01 1.12019777e+00]\n",
      "  [4.40995604e+01 7.55705794e+01 6.92069530e-01]\n",
      "  [7.98267031e+02 3.50261966e+01 4.86430109e+01]\n",
      "  [1.74212085e+01 8.50749038e+01 9.55623031e+01]\n",
      "  [1.75592524e+01 9.16301717e+01 2.91718841e+00]\n",
      "  [7.69659943e+00 7.10867220e+01 2.84580588e+00]\n",
      "  [7.28796770e+00 3.14831126e+01 4.86123562e+01]\n",
      "  [3.27728578e+01 4.00213237e+01 1.66261792e+00]\n",
      "  [9.57951298e+01 2.62488882e+01 7.51662254e-01]\n",
      "  [2.09231520e+02 6.92178567e+01 6.05958700e-01]\n",
      "  [1.42761294e+02 4.34165866e+02 2.21693516e-01]\n",
      "  [5.87734044e+01 4.38394922e+01 1.69068575e-01]\n",
      "  [1.16948610e+01 5.77995886e+01 2.82054543e+00]\n",
      "  [5.04874429e+01 1.90724393e+01 8.27437639e-01]\n",
      "  [1.17888173e+03 6.86356838e+01 1.99437141e+00]\n",
      "  [8.81241632e+00 8.90035383e+01 3.28570604e-01]\n",
      "  [1.88720727e+02 1.57741387e+02 2.10326910e-01]\n",
      "  [4.93417144e+01 2.23745271e+02 2.40415335e+00]\n",
      "  [2.88689494e+01 5.05124893e+01 4.89791036e+01]\n",
      "  [2.02807413e+01 5.50851497e+01 1.65852904e+00]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rg/szb78kyd2cnd60qwd0m1rzvc0000gn/T/ipykernel_73900/870936982.py:5: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  percent_error = abs(predicted_data - test_data)/test_data*100\n"
     ]
    }
   ],
   "source": [
    "# Calculate the mean squared error between the predicted and original test data\n",
    "#mse = ((predicted_data - test_data)**2).mean(axis=None)\n",
    "#print(mse)\n",
    "# Calculate the percentage error between the predicted and original test data\n",
    "#percent_error = abs(predicted_data - test_data)/test_data*100\n",
    "#print(percent_error)\n",
    "\n",
    "# Plot the mean squared error and percentage error\n",
    "#fig, axs = plt.subplots(1, 2, figsize=(10,5))\n",
    "#axs[0].imshow(mse)\n",
    "#axs[0].set_title('Mean Squared Error')\n",
    "#axs[1].imshow(percent_error)\n",
    "#axs[1].set_title('Percentage Error')\n",
    "#plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2c21d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cd3cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901133a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df248e64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c80432",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25df7c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a47317",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1408016",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
